{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "486233ec36e89e593aaf58fa015ac03d",
     "grade": false,
     "grade_id": "cell-8662c8f983b4ba91",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# ELEC 400M / EECE 571M Assignment 2: Neural networks\n",
    "(This assignment is a modified version of an assignment used in ECE 421 at the University of Toronto and kindly made available to us by the instructor.)\n",
    "\n",
    "In this assignment, you will implement a neural network model for multi-class classification. The purpose is to demonstrate an understanding of the basic elements including training of neural network models. Hence, your implementation will be from scratch only using functions from the NumPy library.\n",
    "\n",
    "The neural network you will be implementing has the following structure:\n",
    "* 3 layers: 1 input layer, 1 hidden layer with ReLU activation and 1 output layer with Softmax function Ùè¥£ \n",
    "* The loss function is the Cross Entropy Loss.\n",
    "* Training will be done using Gradient Descent with Momentum. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5c4b1f777717d67e6a7011443bd46bbd",
     "grade": false,
     "grade_id": "cell-814d7b3a3145c5e2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Data Set\n",
    "We again consider the dataset of images of letters in different fonts contained in file notMNIST.npz (which btw is from http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html). This time we consider 10 letters (\"A\" to \"J\"), which are all the letters contained in this data set, and we want to classfiy the images according to the letter they display. The figure below shows 30 randomly selected image samples for the letters.\n",
    "\n",
    "![](sample_images_2.eps)\n",
    "\n",
    "\n",
    "You will apply the function `loadData` given below to load the data set, which includes 18720 images and their labels, which we also refer to as targets. This script organizes the data set into training, validation and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4f49f3888f70a91913e98c176bf8c372",
     "grade": false,
     "grade_id": "cell-356f4913c5215d34",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3f63167b3b48ef91442fff9e52129cd2",
     "grade": false,
     "grade_id": "cell-378d369615cf7a6a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def loadData():\n",
    "    with np.load('notMNIST.npz') as data:\n",
    "        Data, Target = data['images'], data['labels']\n",
    "        np.random.seed(521)\n",
    "        randIndx = np.arange(len(Data))\n",
    "        np.random.shuffle(randIndx)\n",
    "        Data = Data[randIndx]/255.0\n",
    "        Target = Target[randIndx]\n",
    "        trainData, trainTarget = Data[:15000], Target[:15000]\n",
    "        validData, validTarget = Data[15000:16000], Target[15000:16000]\n",
    "        testData, testTarget = Data[16000:], Target[16000:]\n",
    "       \n",
    "    return trainData, validData, testData, trainTarget, validTarget, testTarget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6ed0feb46eaa25e44f926e48b595f0ea",
     "grade": false,
     "grade_id": "cell-596c5760ca09c8db",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Data preprocessing [5 points]\n",
    "\n",
    "Input data: The classification should be based on the $d=28\\times 28=784$ intensity values in an image (as for Assignment 1).\n",
    "\n",
    "Output data: Since you will be performing multi-class classification, the labels will be converted into a one-hot encoding format. \n",
    "\n",
    "Please first briefly explain the meaning of one-hot encoding and why it is used (instead of keeping the numerical label values provided by the data set). State an example for a one-hot encoded label for the data set considered in this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "636512a6eac1a6c967252bdabf4048f3",
     "grade": true,
     "grade_id": "cell-0faa91c6c088b233",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "42bbfcec6879baf85a7898fe88c21da2",
     "grade": false,
     "grade_id": "cell-846dfc32b30e8ce1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now implement a function that one-hot encodes the labels (or targets) for the training, validation and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b4c0e881d76334eebce0a44913ba46ae",
     "grade": true,
     "grade_id": "cell-924299df80c3f9aa",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def convertOneHot(trainTarget, validTarget, testTarget):\n",
    "    trainTargetOneHot = np.zeros([trainTarget.shape[0],10])\n",
    "    trainTargetOneHot[np.arange(trainTarget.size),trainTarget]=1\n",
    "    \n",
    "    validTargetOneHot = np.zeros([validTarget.shape[0],10])\n",
    "    validTargetOneHot[np.arange(validTarget.size),validTarget] = 1\n",
    "    \n",
    "    testTargetOneHot = np.zeros([testTarget.shape[0],10])\n",
    "    testTargetOneHot[np.arange(testTarget.size),testTarget]=1\n",
    "    \n",
    "    \n",
    "    return trainTargetOneHot, validTargetOneHot, testTargetOneHot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1536f677686b7036d2c66d620209e82c",
     "grade": false,
     "grade_id": "cell-7d791d9661633428",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Structure of the network [2 points]\n",
    "\n",
    "Sketch the structure of the network to classify the letters from the data set. Identify the dimensions of the network layers, include the activation functions, and do not forget the bias nodes. (You may sketch this by hand and upload a photo of your sketch.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9b18743021e27e8876becc2b4db99451",
     "grade": true,
     "grade_id": "cell-f90c510b0f8ee6ec",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9ac40fb48e772f9387b11d5675789736",
     "grade": false,
     "grade_id": "cell-59f9a2eba4fddf51",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Helper functions [6 points]\n",
    "To give the implementation of the network some structure, you will first implement five helper functions. \n",
    "\n",
    "Use Numpy arrays for your implementations, and organize data in vectors and matrices as appropriate for compact programming.\n",
    "\n",
    "1. `relu`: This function will accept one argument and return the ReLU activation: \n",
    "    $$\\mathrm{ReLU}(x)=\\max(0,x).$$\n",
    "    \n",
    "2. `softmax`: This function will accept one argument and return the softmax activations:\n",
    "    $$ [\\sigma(\\mathbf{z})]_j = \\frac{\\mathrm{e}^{z_j}}{\\sum\\limits_{k=1}^K\\mathrm{e}^{z_k}},$$ $j=1,2,\\ldots, K$,  for $K$ classes.\n",
    "\n",
    "3. `computeLayer`: This function will accept two arguments, the input vector $\\mathbf{x}$ for a layer and the weight matrix $\\mathbf{W}$, and return a vector $\\mathbf{s}=\\mathbf{W}^T\\mathbf{x}$, i.e., the input to the activation function of the layer (the notation for variables from the textbook is used). Don't forget to account for the bias term (which can be included in an augmented vector $\\mathbf{x}$ as in the textbook).\n",
    "\n",
    "4. `CE`: This function will accept two arguments, the one-hot encoded labels $\\mathbf{y}_n$ and the inputs $\\mathbf{s}_n$ to the softmax function, $n=1,2,\\ldots N$. It will return the cross entropy loss\n",
    "$$\\mathrm{E}_{\\mathrm{in}}=-\\frac{1}{N}\\sum\\limits_{n=1}^N\\sum\\limits_{k=1}^Ky_{n,k}\\log([\\sigma(\\mathbf{s}_n)]_k)$$\n",
    "\n",
    "5. `gradCE`: This function will accept two arguments, the labels and the inputs to the softmax function. It will return the gradient of the cross entropy loss with respect to the inputs (i.e., it returns the sensivity vector for the output layer as introduced in the textbook). \n",
    "\n",
    "First state the analytical expression for the gradient used in `gradCE` and then implement the five helper functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "38319a28929fddb9aeec63a7618aa2c0",
     "grade": true,
     "grade_id": "cell-eb49a8ec15080221",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "**Solution:**\n",
    "\n",
    "The analytical expression for the gradient used in gradCE is given by,\n",
    "\n",
    "$$\\delta^{\\left(L\\right)}_{n}=\\frac{\\partial e_{n}}{\\partial S^{L}_{n}}=\\sigma\\left(S^{L}_{n}\\right)-y_{n}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bd4f5743110984029942f592638733ce",
     "grade": true,
     "grade_id": "cell-d0044385d52cffcf",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "43bb7356ae073f92680f32f0fe49ea76",
     "grade": true,
     "grade_id": "cell-ae7dedf13bb4066f",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def softmax(x):    \n",
    "    op = np.exp(x)/np.sum(np.exp(x))\n",
    "    return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2d5b2370f78ee83853fb13f1308e5329",
     "grade": true,
     "grade_id": "cell-8df181fa3a88e489",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def computeLayer(x,W):\n",
    "    # Assuming x includes bias\n",
    "    return np.matmul(x,W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "119836341edec3cd046d15b6359f3aa7",
     "grade": true,
     "grade_id": "cell-9b34ab1477a6a5da",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def CE(target, prediction):\n",
    "    # My Implementation is n x k\n",
    "    return (-1.0/target.shape[0])*np.sum(np.multiply(target,np.log(softmax(prediction))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4067e14fdfd9fe7938309d994ad3436b",
     "grade": true,
     "grade_id": "cell-7da4a6821dc7e0ac",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def gradCE(target, prediction):\n",
    "    # Returns Sensitivity Vector for Layer L\n",
    "    return softmax(prediction)-target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7e3c25a1bd38eb37acace72f3c0a78c2",
     "grade": false,
     "grade_id": "cell-37acd78048c1b219",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Backpropagation [2 points]\n",
    "\n",
    "The training of the network will be done via backpropagation. First derive the following gradients:\n",
    "1. $\\frac{\\partial E_{\\mathrm{in}}}{\\partial \\mathbf{W}^{\\mathrm{o}}}$, where $\\mathbf{W}^{\\mathrm{o}}$ is the weight matrix of the output layer.\n",
    "\n",
    "2. $\\frac{\\partial E_{\\mathrm{in}}}{\\partial \\mathbf{W}^{\\mathrm{h}}}$, where $\\mathbf{W}^{\\mathrm{h}}$ is the weight matrix of the hidden layer.\n",
    "\n",
    "Write the results using the steps and notation used in the textbook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6f519d4da4c6b663b42fa12c0082ee3c",
     "grade": true,
     "grade_id": "cell-ac7e24b5b1eee343",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "**Solution:**\n",
    "\n",
    "1. $\\frac{\\partial E_{in}}{\\partial W^{0}}$ where $W^{0}$ is the weight matrix of the output layer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7e11084bb8f343b86fd223436e42eed9",
     "grade": false,
     "grade_id": "cell-ca564be205805d5c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Network training [8 points]\n",
    "\n",
    "Implement a function to train the network. The function uses the helper functions from above. The optimization technique for backpropagation will be Gradient Descent with Momentum:\n",
    "$$\\mathbf{V}(t)=\\alpha \\mathbf{V}(t-1)-\\eta\\frac{\\partial E_{\\mathrm{in}}}{\\partial \\mathbf{W}(t)}$$\n",
    "and \n",
    "$$\\mathbf{W}(t+1)=\\mathbf{W}(t)+\\mathbf{V}(t),$$\n",
    "where $\\eta$ is the learning rate and $\\alpha$ is the momentum hyperparameter.\n",
    "\n",
    "The training function accepts the following inputs:  training data (features), training labels, weight matrix of the hidden layer, weight matrix of the output layer, number of iterations, parameters $\\eta$ and $\\alpha$, validation data, validation labels, test data, test labels. The validation and test inputs are initialized to \"None\" and need not be passed on. You will also need to initialize the velocity matrices $\\mathbf{V}$ for both hidden layer and output layer weights to small values, e.g. $10^{-5}%$.\n",
    "\n",
    "The function outputs the updated weight matrices, the losses and classification accuracies for the training data, and if validation and test inputs were provided, then it also outputs the classification accuracies for the validation and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "58dcb68f57a14d8a1375ea4f625ea7b6",
     "grade": true,
     "grade_id": "cell-f1fd1f8de32bae42",
     "locked": false,
     "points": 8,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e5aa8cd9678c46a432c9946a317bbdb3",
     "grade": false,
     "grade_id": "cell-8f062bae545cfea3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Network test [4 points]\n",
    "\n",
    "Write a script that constructs the neural network.\n",
    "\n",
    "Initialize your weight matrices by drawing the elements i.i.d. at random from a zero-mean Gaussian distribution with variance equal to $$\\sigma_w^2=\\frac{2}{\\mbox{# of input nodes + # of output nodes}}$$ (Xavier normalization http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf) \n",
    "\n",
    "Build a network with 1000 hidden units and train it for 200 epochs using $\\alpha=0.9$ and $\\eta=10^{-5}$. Plot the training, validation and testing accuracy curves. State the training, validation and testing accuracies after training. Show the plot and the accuracies in the next markdown cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "46b789c7c5c35a54f544d8157558b0cf",
     "grade": true,
     "grade_id": "cell-69365489da7f9c07",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "de33f35d8e38fe8607e30cc83fc7146c",
     "grade": true,
     "grade_id": "cell-71e0b1ff4567d3c3",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3855c5efdf7fd347c49f1ab4e3c482f6",
     "grade": false,
     "grade_id": "cell-bfd49bf15d3f0b3e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Hyperparameter investigation [3 points]\n",
    "\n",
    "Continue to use $\\alpha=0.9$ and $\\eta=10^{-5}$.\n",
    "\n",
    "Test your network with 500, 1500, 2500 hidden nodes and train for 200 epochs. Comment based on the validation accuracy after how many epochs training could be terminated early. \n",
    "\n",
    "Plot the training and validation accuracy curves for all three network sizes and 200 training epochs, and report the test accuracy for your selected network size and training length. Show the plot and the accuracies in the next markdown cell.\n",
    "\n",
    "(Training of the large network for 200 epochs should take about 30-60 mins.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8adf631ac20e85951543db6f7602e0c5",
     "grade": true,
     "grade_id": "cell-166556fcc63e2168",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f56b4a3a537d340f5e79f2a13c4626bf",
     "grade": true,
     "grade_id": "cell-88bbf03aa902e44e",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
